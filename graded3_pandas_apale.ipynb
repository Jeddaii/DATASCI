{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174e376c",
   "metadata": {
    "id": "174e376c"
   },
   "source": [
    "# Zomato Exercise\n",
    "\n",
    "Jedrek Mari Gabriel G. Apale\n",
    "\n",
    "Data100 - S17\n",
    "\n",
    "12174998 - BS-Electronics Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84fdf3",
   "metadata": {
    "id": "2d84fdf3"
   },
   "source": [
    "Zomato is a restaurant aggregator website. The platform provides information, menus and user-reviews of restaurants as well as food delivery options from partner restaurants in select cities. You have been provided 3 datasets:\n",
    "\n",
    "- zomato.csv contains restaurant information like average_cost_for_two, cuisines\n",
    "- location.csv contains location of the restaurants like address, city, locality & etc\n",
    "- ratings.csv contains aggregate rating for each restaurant\n",
    "\n",
    "The different files are connected using the `id` columns which can be found in the different files. The id column is a unique identifier to represent a restaurant. You can use this to **merge** the different files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337de5f",
   "metadata": {
    "id": "5337de5f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77605fbc",
   "metadata": {
    "id": "77605fbc"
   },
   "source": [
    "1. Merge the zomato, location & ratings file into a signle dataframe and store it to the `merged_df` variable **(3pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddbd0bb1",
   "metadata": {
    "id": "ddbd0bb1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "zomato = pd.read_csv(\"D:\\\\datasci\\\\GRADED3\\\\zomato.csv\")\n",
    "location = pd.read_csv(\"D:\\\\datasci\\\\GRADED3\\\\location.csv\")\n",
    "ratings = pd.read_csv(\"D:\\\\datasci\\\\GRADED3\\\\ratings.csv\")\n",
    "\n",
    "merged_df =  pd.merge(location, ratings, on=\"id\") \n",
    "merged_df = pd.merge(merged_df, zomato, on=\"id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a86a44",
   "metadata": {
    "id": "b2a86a44"
   },
   "outputs": [],
   "source": [
    "assert (6830, 35)==merged_df.shape\n",
    "\n",
    "cols = ['id', 'address', 'city', 'city_id', 'country_id', 'latitude',\n",
    "       'locality', 'locality_verbose', 'longitude', 'zipcode',\n",
    "       'aggregate_rating', 'rating_color', 'rating_text', 'votes',\n",
    "       'average_cost_for_two', 'book_url', 'cuisines', 'currency', 'deeplink',\n",
    "       'events_url', 'featured_image', 'has_online_delivery',\n",
    "       'has_table_booking', 'include_bogo_offers', 'is_book_form_web_view',\n",
    "       'is_delivering_now', 'is_table_reservation_supported',\n",
    "       'is_zomato_book_res', 'menu_url', 'mezzo_provider', 'name',\n",
    "       'photos_url', 'price_range', 'thumb', 'url']\n",
    "\n",
    "assert sorted(merged_df.columns) == sorted(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02223abe",
   "metadata": {
    "id": "02223abe"
   },
   "source": [
    "2. Create a function that returns the average aggregate rating for each city. Expected returned value is a Series datatype which contains name of city as index and average aggregate rating as value. **(2pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7d8f34",
   "metadata": {
    "id": "bd7d8f34"
   },
   "outputs": [],
   "source": [
    "def exercise_2(merged_df):\n",
    "    \n",
    "    average = merged_df.groupby('city')['aggregate_rating'].mean()\n",
    "    \n",
    "    return average\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e5b4c1",
   "metadata": {
    "id": "10e5b4c1"
   },
   "outputs": [],
   "source": [
    "res_series = exercise_2(merged_df)\n",
    "assert True == np.isclose(3.302075, res_series[res_series.index == 'Pasay City'],\n",
    "                          rtol=1e-05, atol=1e-08, equal_nan=False)[0]\n",
    "assert True == np.isclose(1.890741, res_series[res_series.index == 'Valenzuela City'],\n",
    "                          rtol=1e-05, atol=1e-08, equal_nan=False)[0]\n",
    "assert True == np.isclose(1.558333, res_series[res_series.index == 'Malabon City'],\n",
    "                          rtol=1e-05, atol=1e-08, equal_nan=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db591ac",
   "metadata": {
    "id": "5db591ac"
   },
   "source": [
    "3. Using the apply function of pandas convert the rating_text to a numeric equivalent. You are to introduce a new column in merged_df called `rating_numeric` which is based on the value from rating_text: **(3pts)**\n",
    "\n",
    "Excellent = 5 <br>\n",
    "Very Good = 4 <br>\n",
    "Good = 3 <br>\n",
    "Average = 2 <br>\n",
    "Poor = 1 <br>\n",
    "Not rated = 0 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41293771",
   "metadata": {
    "id": "41293771"
   },
   "outputs": [],
   "source": [
    "rating = {\n",
    "    \"Excellent\": 5,\n",
    "    \"Very Good\": 4,\n",
    "    \"Good\": 3,\n",
    "    \"Average\": 2,\n",
    "    \"Poor\": 1,\n",
    "    \"Not rated\": 0\n",
    "}\n",
    "\n",
    "merged_df[\"rating_numeric\"] = merged_df[\"rating_text\"].apply(lambda x: rating.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62df922",
   "metadata": {
    "id": "c62df922"
   },
   "outputs": [],
   "source": [
    "assert 868 == merged_df[merged_df.rating_numeric == 0].shape[0]\n",
    "assert True == ('rating_numeric' in merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec4197",
   "metadata": {
    "id": "97ec4197"
   },
   "source": [
    "4. Create a function which filters the merged dataframe to only contain rows coming in from a specific city. Expected returned value is a dataframe **(2pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9773b18e",
   "metadata": {
    "id": "9773b18e"
   },
   "outputs": [],
   "source": [
    "def exercise_4(merged_df, city):\n",
    "\n",
    "    filtered_df = merged_df[merged_df['city'] == city]\n",
    "    \n",
    "    return filtered_df\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca29a81",
   "metadata": {
    "id": "1ca29a81"
   },
   "outputs": [],
   "source": [
    "assert 'Makati City' == exercise_4(merged_df, 'Makati City').city.unique()[0]\n",
    "assert (976, 36) == exercise_4(merged_df, 'Makati City').shape\n",
    "\n",
    "assert 'Mandaluyong City' == exercise_4(merged_df, 'Mandaluyong City').city.unique()[0]\n",
    "assert (443, 36) == exercise_4(merged_df, 'Mandaluyong City').shape\n",
    "\n",
    "assert (0, 36) == exercise_4(merged_df, 'Quezon  City').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7bf3c1",
   "metadata": {
    "id": "ca7bf3c1"
   },
   "source": [
    "5. Create a function to filter the dataframe to only contain certain columns passed in the function. Expected returned value is a dataframe **(1pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59787577",
   "metadata": {
    "id": "59787577"
   },
   "outputs": [],
   "source": [
    "def exercise_5(merged_df, cols_to_filter):\n",
    "        \n",
    "    filter_df = merged_df[cols_to_filter]\n",
    "    \n",
    "    return filter_df \n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da27c054",
   "metadata": {
    "id": "da27c054"
   },
   "outputs": [],
   "source": [
    "cols = ['name', 'cuisines', 'city', 'aggregate_rating']\n",
    "assert sorted(cols) == sorted(exercise_5(merged_df, cols).columns)\n",
    "assert (6830, 4) == exercise_5(merged_df, cols).shape\n",
    "\n",
    "cols = ['average_cost_for_two', 'book_url', 'cuisines', 'currency', 'deeplink',\n",
    "       'events_url', 'featured_image', 'has_online_delivery',\n",
    "       'has_table_booking', 'include_bogo_offers', 'is_book_form_web_view']\n",
    "assert sorted(cols) == sorted(exercise_5(merged_df, cols).columns)\n",
    "assert (6830, 11) == exercise_5(merged_df, cols).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c7e2e",
   "metadata": {
    "id": "d69c7e2e"
   },
   "source": [
    "6.  What is the most common restaurant name in the dataset? **(2pts)** Write down your answer and show code used to come up with the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9cdab1",
   "metadata": {
    "id": "cf9cdab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common restaurant name in the dataset is Starbucks, which appeared 99 times.\n"
     ]
    }
   ],
   "source": [
    "cname_df = merged_df.groupby(\"name\").size()\n",
    "num = cname_df.max()\n",
    "cname_df = cname_df.idxmax()\n",
    "\n",
    "\n",
    "print(f\"The most common restaurant name in the dataset is {cname_df}, which appeared {num} times.\")\n",
    "\n",
    "#To come up with the code, the dataset in the variable merged_df was grouped by its column \"name\". The usage of size() allows the program to count how\n",
    "#many times a unique restaurant name appears in the group. This was then stored in a variable cname_df. The new variable was then used to find the \n",
    "#maximum or greatest amount of times a restaurant name appeared using max(). Lastly, to find which restaurant it was, we used the idxmax() function to\n",
    "#return to us the index with the greatest number of times that the name has appeared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675b4b1",
   "metadata": {
    "id": "7675b4b1"
   },
   "source": [
    "7. Which restaurant has the most expensive average cost for two? **(2pts)** Write down your answer and show code used to come up with the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b447b440",
   "metadata": {
    "id": "b447b440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The restaurant with the most expensive average cost for two is The Tasting Room, which costs around P10000.\n"
     ]
    }
   ],
   "source": [
    "nameave_df = merged_df[[\"name\",\"average_cost_for_two\"]]\n",
    "maxave = nameave_df[\"average_cost_for_two\"].max()\n",
    "maxname_idx = nameave_df[\"average_cost_for_two\"].idxmax()\n",
    "maxname = nameave_df[\"name\"][maxname_idx]\n",
    "\n",
    "print(f\"The restaurant with the most expensive average cost for two is {maxname}, which costs around P{maxave}.\")\n",
    "#First, I put the necessary columns from the dataset in merged_df into nameave_df. Following this, I used max() for the column of \"average_cost_for_two\"\n",
    "#to find the maximum value in that specific column, Placing it in the variable maxave to get the value. Next, I used idxmax() in order to find the index that contains the highest value in that column, placing\n",
    "#it in variable maxname_idx, which will help us find the name of the restaurant. Lastly, I used the column of \"name\" in the variable nameave_df and the\n",
    "#index that we got from maxname_idx in order to find the restaurant of that index, which is The Tasting Room."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af873fb7",
   "metadata": {
    "id": "af873fb7"
   },
   "source": [
    "8. How many restaurants do not have a zipcode? **(1pt)** Write down your answer and show code used to come up with the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43f1234a",
   "metadata": {
    "id": "43f1234a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6713 restaurants which do not have a zipcode.\n"
     ]
    }
   ],
   "source": [
    "zip = merged_df[\"zipcode\"]\n",
    "\n",
    "no_zip = zip.isnull() \n",
    "no_zip = no_zip.sum()\n",
    "\n",
    "print(f\"There are {no_zip} restaurants which do not have a zipcode.\")\n",
    "#First, I put the column \"zipcode\" from the dataframe merged_df into a variable named zip. After that, I used the isnull() function in order to check\n",
    "#which rows had null (no zipcode) zipcodes and placed it in the variable no_zip. I then added the amount of true outputs using the sum() function to get the number of restaurants \n",
    "#without a zipcode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347ac03",
   "metadata": {
    "id": "9347ac03"
   },
   "source": [
    "9. How many restaurants in the dataset allow online delivery? **(1pt)** Write down your answer and show code used to come up with the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b62212",
   "metadata": {
    "id": "24b62212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 restaurants that allow online delivery.\n"
     ]
    }
   ],
   "source": [
    "online = merged_df[\"has_online_delivery\"]\n",
    "\n",
    "online = online == 1\n",
    "online = online.sum() \n",
    "\n",
    "print(f\"There are {online} restaurants that allow online delivery.\")\n",
    "#First, I extracted the \"has_online_delivery\" column from merged_df into the variable online. Then, I compared the values of the data in online to 1,\n",
    "#as the .csv file only gave values either 0 (No) or 1 (Yes). If the condition is true, it will return true and vice-versa. Using the function sum()\n",
    "#allows us to see the number of restaurants that has online delivery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c7aa3",
   "metadata": {
    "id": "7f2c7aa3"
   },
   "source": [
    "10. Which locatlity has more expensive food? Poblacion or Salcedo Village? **(3pts)** Write down your answer and show code used to come up with the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb7ce16",
   "metadata": {
    "id": "8fb7ce16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salcedo Village has more expensive food than Poblacion.\n"
     ]
    }
   ],
   "source": [
    "PSlocalcost = merged_df[[\"locality\", \"average_cost_for_two\"]]\n",
    "\n",
    "meanpobla = PSlocalcost[PSlocalcost[\"locality\"] == \"Poblacion\"][\"average_cost_for_two\"].mean()\n",
    "meansalcedo = PSlocalcost[PSlocalcost[\"locality\"] == \"Salcedo Village\"][\"average_cost_for_two\"].mean()\n",
    "\n",
    "if meanpobla > meansalcedo:\n",
    "    print(\"Poblacion has more expensive food than Salcedo Village.\")\n",
    "else:\n",
    "    print(\"Salcedo Village has more expensive food than Poblacion.\")\n",
    "\n",
    "#First, I got the locality and average_cost_for_two from the merged_df into the variable PSlocalcost. Then, I got the mean for Poblacion by filtering locality\n",
    "#to have Poblacion under it, which then selects the rows that have it and get its mean using mean(). The same steps are repeated for Salcedo Village.\n",
    "#The reason as to why I used mean as it gives us the average costs of each restaurant present in the vicinity. Then, I compared each mean to see which\n",
    "#is more expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b21fd1-cbd3-4e5b-8cb2-ae974872778f",
   "metadata": {},
   "source": [
    "References:\n",
    "1. Pandas. (n.d.). Merge, join, concatenate and compare — pandas 2.1.1 documentation. pandas - Python Data Analysis Library. Retrieved September 27, 2024, from https://pandas.pydata.org/docs/user_guide/merging.html\n",
    "\n",
    "2. Pandas. (n.d.). Pandas.DataFrame.apply — pandas 2.0.3 documentation. pandas - Python Data Analysis Library. Retrieved September 27, 2024, from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "\n",
    "3. Saturn Cloud. (2023, June 19). How to count Nan and null values in a pandas DataFrame. Saturn Cloud | #1 Rated ML Platform. Retrieved September 27, 2024, from https://saturncloud.io/blog/how-to-count-nan-and-null-values-in-a-pandas-dataframe/\n",
    "\n",
    "4. Saturn Cloud. (2023, June 19). What Is the Most Efficient Way of Counting Occurrences in Pandas. Saturn Cloud | #1 Rated ML Platform. Retrieved September 27, 2024, from https://saturncloud.io/blog/what-is-the-most-efficient-way-of-counting-occurrences-in-pandas/\n",
    "\n",
    "5. W3schools. (n.d.). Pandas DataFrame idxmax() Method. W3Schools Online Web Tutorials. Retrieved September 27, 2024, from https://www.w3schools.com/python/pandas/ref_df_idxmax.asp\n",
    "\n",
    "6. W3schools. (n.d.). Python dictionary get() method. W3Schools Online Web Tutorials. Retrieved September 27, 2024, from"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
